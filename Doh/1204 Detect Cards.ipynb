{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive threshold levels\n",
    "BKG_THRESH = 60\n",
    "CARD_THRESH = 30\n",
    "\n",
    "# Width and height of card corner, where rank and suit are\n",
    "CORNER_WIDTH = 32\n",
    "CORNER_HEIGHT = 84\n",
    "\n",
    "# Dimensions of rank train images\n",
    "RANK_WIDTH = 70\n",
    "RANK_HEIGHT = 125\n",
    "\n",
    "# Dimensions of suit train images\n",
    "SUIT_WIDTH = 70\n",
    "SUIT_HEIGHT = 100\n",
    "\n",
    "RANK_DIFF_MAX = 2000\n",
    "SUIT_DIFF_MAX = 700\n",
    "\n",
    "CARD_MAX_AREA = 1200000\n",
    "CARD_MIN_AREA = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('heart3.jpg')\n",
    "im_bw = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "_, thresh = cv2.threshold(im_bw,120,255,cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts,hier = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "index_sort = sorted(range(len(cnts)), key=lambda i : cv2.contourArea(cnts[i]),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts_sort = []\n",
    "hier_sort = []\n",
    "cnt_is_card = np.zeros(len(cnts),dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in index_sort:\n",
    "    cnts_sort.append(cnts[i])\n",
    "    hier_sort.append(hier[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1,  2,  4, -1], dtype=int32),\n",
       " array([ 7,  5, -1,  3], dtype=int32),\n",
       " array([ 8,  6, -1,  3], dtype=int32),\n",
       " array([10,  8, -1,  3], dtype=int32),\n",
       " array([ 6,  4, -1,  3], dtype=int32),\n",
       " array([ 5, -1, -1,  3], dtype=int32),\n",
       " array([ 9,  7, -1,  3], dtype=int32),\n",
       " array([-1,  9, -1,  3], dtype=int32),\n",
       " array([ 1, -1, -1, -1], dtype=int32),\n",
       " array([ 2,  0, -1, -1], dtype=int32),\n",
       " array([ 3,  1, -1, -1], dtype=int32)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hier_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671153.0\n",
      "14521.5\n",
      "12446.5\n",
      "11069.5\n",
      "3335.5\n",
      "2984.5\n",
      "2660.0\n",
      "2207.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cnts_sort)):\n",
    "    size = cv2.contourArea(cnts_sort[i])\n",
    "    peri = cv2.arcLength(cnts_sort[i],True)\n",
    "    approx = cv2.approxPolyDP(cnts_sort[i],0.01*peri,True)\n",
    "    print(size)\n",
    "    if ((size < CARD_MAX_AREA) and (size > CARD_MIN_AREA)\n",
    "        and (hier_sort[i][3] == -1) and (len(approx) == 4)):\n",
    "        cnt_is_card[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnts_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_is_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards.append(preprocess_card(cnts_sort[0],img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_card(contour, image):\n",
    "    \"\"\"Uses contour to find information about the query card. Isolates rank\n",
    "    and suit images from the card.\"\"\"\n",
    "\n",
    "    # Initialize new Query_card object\n",
    "    qCard = Query_card()\n",
    "\n",
    "    qCard.contour = contour\n",
    "\n",
    "    # Find perimeter of card and use it to approximate corner points\n",
    "    peri = cv2.arcLength(contour,True)\n",
    "    approx = cv2.approxPolyDP(contour,0.01*peri,True)\n",
    "    pts = np.float32(approx)\n",
    "    qCard.corner_pts = pts\n",
    "\n",
    "    # Find width and height of card's bounding rectangle\n",
    "    x,y,w,h = cv2.boundingRect(contour)\n",
    "    qCard.width, qCard.height = w, h\n",
    "\n",
    "    # Find center point of card by taking x and y average of the four corners.\n",
    "    average = np.sum(pts, axis=0)/len(pts)\n",
    "    cent_x = int(average[0][0])\n",
    "    cent_y = int(average[0][1])\n",
    "    qCard.center = [cent_x, cent_y]\n",
    "\n",
    "    # Warp card into 200x300 flattened image using perspective transform\n",
    "    qCard.warp = flattener(image, pts, w, h)\n",
    "\n",
    "    # Grab corner of warped card image and do a 4x zoom\n",
    "    Qcorner = qCard.warp[0:CORNER_HEIGHT, 0:CORNER_WIDTH]\n",
    "    Qcorner_zoom = cv2.resize(Qcorner, (0,0), fx=4, fy=4)\n",
    "\n",
    "    # Sample known white pixel intensity to determine good threshold level\n",
    "    white_level = Qcorner_zoom[15,int((CORNER_WIDTH*4)/2)]\n",
    "    thresh_level = white_level - CARD_THRESH\n",
    "    if (thresh_level <= 0):\n",
    "        thresh_level = 1\n",
    "    retval, query_thresh = cv2.threshold(Qcorner_zoom, thresh_level, 255, cv2. THRESH_BINARY_INV)\n",
    "    \n",
    "    # Split in to top and bottom half (top shows rank, bottom shows suit)\n",
    "    Qrank = query_thresh[20:185, 0:128]\n",
    "    Qsuit = query_thresh[186:336, 0:128]\n",
    "\n",
    "    # Find rank contour and bounding rectangle, isolate and find largest contour\n",
    "    Qrank_cnts, hier = cv2.findContours(Qrank, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    Qrank_cnts = sorted(Qrank_cnts, key=cv2.contourArea,reverse=True)\n",
    "\n",
    "    # Find bounding rectangle for largest contour, use it to resize query rank\n",
    "    # image to match dimensions of the train rank image\n",
    "    if len(Qrank_cnts) != 0:\n",
    "        x1,y1,w1,h1 = cv2.boundingRect(Qrank_cnts[0])\n",
    "        Qrank_roi = Qrank[y1:y1+h1, x1:x1+w1]\n",
    "        Qrank_sized = cv2.resize(Qrank_roi, (RANK_WIDTH,RANK_HEIGHT), 0, 0)\n",
    "        qCard.rank_img = Qrank_sized\n",
    "\n",
    "    # Find suit contour and bounding rectangle, isolate and find largest contour\n",
    "    Qsuit_cnts, hier = cv2.findContours(Qsuit, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    Qsuit_cnts = sorted(Qsuit_cnts, key=cv2.contourArea,reverse=True)\n",
    "    \n",
    "    # Find bounding rectangle for largest contour, use it to resize query suit\n",
    "    # image to match dimensions of the train suit image\n",
    "    if len(Qsuit_cnts) != 0:\n",
    "        x2,y2,w2,h2 = cv2.boundingRect(Qsuit_cnts[0])\n",
    "        Qsuit_roi = Qsuit[y2:y2+h2, x2:x2+w2]\n",
    "        Qsuit_sized = cv2.resize(Qsuit_roi, (SUIT_WIDTH, SUIT_HEIGHT), 0, 0)\n",
    "        qCard.suit_img = Qsuit_sized\n",
    "\n",
    "    return qCard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query_card:\n",
    "    \"\"\"Structure to store information about query cards in the camera image.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.contour = [] # Contour of card\n",
    "        self.width, self.height = 0, 0 # Width and height of card\n",
    "        self.corner_pts = [] # Corner points of card\n",
    "        self.center = [] # Center point of card\n",
    "        self.warp = [] # 200x300, flattened, grayed, blurred image\n",
    "        self.rank_img = [] # Thresholded, sized image of card's rank\n",
    "        self.suit_img = [] # Thresholded, sized image of card's suit\n",
    "        self.best_rank_match = \"Unknown\" # Best matched rank\n",
    "        self.best_suit_match = \"Unknown\" # Best matched suit\n",
    "        self.rank_diff = 0 # Difference between rank image and best matched train rank image\n",
    "        self.suit_diff = 0 # Difference between suit image and best matched train suit image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattener(image, pts, w, h):\n",
    "    \"\"\"Flattens an image of a card into a top-down 200x300 perspective.\n",
    "    Returns the flattened, re-sized, grayed image.\n",
    "    See www.pyimagesearch.com/2014/08/25/4-point-opencv-getperspective-transform-example/\"\"\"\n",
    "    temp_rect = np.zeros((4,2), dtype = \"float32\")\n",
    "    \n",
    "    s = np.sum(pts, axis = 2)\n",
    "\n",
    "    tl = pts[np.argmin(s)]\n",
    "    br = pts[np.argmax(s)]\n",
    "\n",
    "    diff = np.diff(pts, axis = -1)\n",
    "    tr = pts[np.argmin(diff)]\n",
    "    bl = pts[np.argmax(diff)]\n",
    "\n",
    "    # Need to create an array listing points in order of\n",
    "    # [top left, top right, bottom right, bottom left]\n",
    "    # before doing the perspective transform\n",
    "\n",
    "    if w <= 0.8*h: # If card is vertically oriented\n",
    "        temp_rect[0] = tl\n",
    "        temp_rect[1] = tr\n",
    "        temp_rect[2] = br\n",
    "        temp_rect[3] = bl\n",
    "\n",
    "    if w >= 1.2*h: # If card is horizontally oriented\n",
    "        temp_rect[0] = bl\n",
    "        temp_rect[1] = tl\n",
    "        temp_rect[2] = tr\n",
    "        temp_rect[3] = br\n",
    "\n",
    "    # If the card is 'diamond' oriented, a different algorithm\n",
    "    # has to be used to identify which point is top left, top right\n",
    "    # bottom left, and bottom right.\n",
    "    \n",
    "    if w > 0.8*h and w < 1.2*h: #If card is diamond oriented\n",
    "        # If furthest left point is higher than furthest right point,\n",
    "        # card is tilted to the left.\n",
    "        if pts[1][0][1] <= pts[3][0][1]:\n",
    "            # If card is titled to the left, approxPolyDP returns points\n",
    "            # in this order: top right, top left, bottom left, bottom right\n",
    "            temp_rect[0] = pts[1][0] # Top left\n",
    "            temp_rect[1] = pts[0][0] # Top right\n",
    "            temp_rect[2] = pts[3][0] # Bottom right\n",
    "            temp_rect[3] = pts[2][0] # Bottom left\n",
    "\n",
    "        # If furthest left point is lower than furthest right point,\n",
    "        # card is tilted to the right\n",
    "        if pts[1][0][1] > pts[3][0][1]:\n",
    "            # If card is titled to the right, approxPolyDP returns points\n",
    "            # in this order: top left, bottom left, bottom right, top right\n",
    "            temp_rect[0] = pts[0][0] # Top left\n",
    "            temp_rect[1] = pts[3][0] # Top right\n",
    "            temp_rect[2] = pts[2][0] # Bottom right\n",
    "            temp_rect[3] = pts[1][0] # Bottom left\n",
    "            \n",
    "        \n",
    "    maxWidth = 200\n",
    "    maxHeight = 300\n",
    "\n",
    "    # Create destination array, calculate perspective transform matrix,\n",
    "    # and warp card image\n",
    "    dst = np.array([[0,0],[maxWidth-1,0],[maxWidth-1,maxHeight-1],[0, maxHeight-1]], np.float32)\n",
    "    M = cv2.getPerspectiveTransform(temp_rect,dst)\n",
    "    warp = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    warp = cv2.cvtColor(warp,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        \n",
    "\n",
    "    return warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:663: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'cv::arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-c08d5b2c91d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_rank_match\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_suit_match\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank_diff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuit_diff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch_card\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_ranks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_suits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-97-dbad884e870c>\u001b[0m in \u001b[0;36mmatch_card\u001b[1;34m(qCard, train_ranks, train_suits)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mTrank\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_ranks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                 \u001b[0mdiff_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqCard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrank\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m                 \u001b[0mrank_diff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.1) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:663: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'cv::arithm_op'\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "cards[k].best_rank_match,cards[k].best_suit_match,cards[k].rank_diff,cards[k].suit_diff = match_card(cards[k],train_ranks,train_suits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_card(qCard, train_ranks, train_suits):\n",
    "    \"\"\"Finds best rank and suit matches for the query card. Differences\n",
    "    the query card rank and suit images with the train rank and suit images.\n",
    "    The best match is the rank or suit image that has the least difference.\"\"\"\n",
    "\n",
    "    best_rank_match_diff = 10000\n",
    "    best_suit_match_diff = 10000\n",
    "    best_rank_match_name = \"Unknown\"\n",
    "    best_suit_match_name = \"Unknown\"\n",
    "    i = 0\n",
    "\n",
    "    # If no contours were found in query card in preprocess_card function,\n",
    "    # the img size is zero, so skip the differencing process\n",
    "    # (card will be left as Unknown)\n",
    "    if (len(qCard.rank_img) != 0) and (len(qCard.suit_img) != 0):\n",
    "        \n",
    "        # Difference the query card rank image from each of the train rank images,\n",
    "        # and store the result with the least difference\n",
    "        for Trank in train_ranks:\n",
    "\n",
    "                diff_img = cv2.absdiff(qCard.rank_img, Trank.img)\n",
    "                rank_diff = int(np.sum(diff_img)/255)\n",
    "                \n",
    "                if rank_diff < best_rank_match_diff:\n",
    "                    best_rank_diff_img = diff_img\n",
    "                    best_rank_match_diff = rank_diff\n",
    "                    best_rank_name = Trank.name\n",
    "\n",
    "        # Same process with suit images\n",
    "        for Tsuit in train_suits:\n",
    "                \n",
    "                diff_img = cv2.absdiff(qCard.suit_img, Tsuit.img)\n",
    "                suit_diff = int(np.sum(diff_img)/255)\n",
    "                \n",
    "                if suit_diff < best_suit_match_diff:\n",
    "                    best_suit_diff_img = diff_img\n",
    "                    best_suit_match_diff = suit_diff\n",
    "                    best_suit_name = Tsuit.name\n",
    "\n",
    "    # Combine best rank match and best suit match to get query card's identity.\n",
    "    # If the best matches have too high of a difference value, card identity\n",
    "    # is still Unknown\n",
    "    if (best_rank_match_diff < RANK_DIFF_MAX):\n",
    "        best_rank_match_name = best_rank_name\n",
    "\n",
    "    if (best_suit_match_diff < SUIT_DIFF_MAX):\n",
    "        best_suit_match_name = best_suit_name\n",
    "\n",
    "    # Return the identiy of the card and the quality of the suit and rank match\n",
    "    print(best_rank_match_name, best_suit_match_name, best_rank_match_diff, best_suit_match_diff)\n",
    "    return best_rank_match_name, best_suit_match_name, best_rank_match_diff, best_suit_match_diff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_ranks:\n",
    "    \"\"\"Structure to store information about train rank images.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.img = [] # Thresholded, sized rank image loaded from hard drive\n",
    "        self.name = \"Placeholder\"\n",
    "\n",
    "class Train_suits:\n",
    "    \"\"\"Structure to store information about train suit images.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.img = [] # Thresholded, sized suit image loaded from hard drive\n",
    "        self.name = \"Placeholder\"\n",
    "\n",
    "### Functions ###\n",
    "def load_ranks(filepath):\n",
    "    \"\"\"Loads rank images from directory specified by filepath. Stores\n",
    "    them in a list of Train_ranks objects.\"\"\"\n",
    "\n",
    "    train_ranks = []\n",
    "    i = 0\n",
    "    \n",
    "    for Rank in ['Ace','Two','Three','Four','Five','Six','Seven',\n",
    "                 'Eight','Nine','Ten','Jack','Queen','King']:\n",
    "        train_ranks.append(Train_ranks())\n",
    "        train_ranks[i].name = Rank\n",
    "        filename = Rank + '.jpg'\n",
    "        train_ranks[i].img = cv2.imread(filepath+filename, cv2.IMREAD_GRAYSCALE)\n",
    "        i = i + 1\n",
    "\n",
    "    return train_ranks\n",
    "\n",
    "def load_suits(filepath):\n",
    "    \"\"\"Loads suit images from directory specified by filepath. Stores\n",
    "    them in a list of Train_suits objects.\"\"\"\n",
    "\n",
    "    train_suits = []\n",
    "    i = 0\n",
    "    \n",
    "    for Suit in ['Spades','Diamonds','Clubs','Hearts']:\n",
    "        train_suits.append(Train_suits())\n",
    "        train_suits[i].name = Suit\n",
    "        filename = Suit + '.jpg'\n",
    "        train_suits[i].img = cv2.imread(filepath+filename, cv2.IMREAD_GRAYSCALE)\n",
    "        i = i + 1\n",
    "\n",
    "    return train_suits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ranks = load_ranks('/Card_Imgs/')\n",
    "train_suits = load_suits('/Card_Imgs/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
